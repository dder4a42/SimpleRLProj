# PPO configuration for MuJoCo continuous control tasks

# Environment
env:
  name: HalfCheetah-v4

# Network architecture (MLP for continuous actions)
network:
  hidden_dim: 64
  hidden_layers: 2

# PPO-specific settings
ppo:
  gae_lambda: 0.95
  clip_range: 0.2
  entropy_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  rollout_steps: 2048
  num_epochs: 10
  minibatch_size: 64

# Training settings
training:
  total_steps: 1000000
  gamma: 0.99
  lr: 0.0003
  lr_final: 0.0003
  lr_decay_steps: 1000000
  batch_size: 64
  buffer_size: 2048
  warmup_steps: 0
  target_update_freq: 1
  target_update_mode: "soft"
  tau: 0.005
  grad_clip: 0.5
  updates_per_step: 1
  use_amp: false
  reward_clip: null

# Logging
logging:
  log_interval: 10000
  save_interval: 250000
  log_dir: "logs"
  save_dir: "checkpoints"

# Resume training
resume:
  checkpoint: null

# Parallel environments
parallel:
  num_envs: 8
  async: false
  seed: 42
  enable_cpu_monitor: true
